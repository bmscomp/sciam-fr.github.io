= Un design √©volutif pour des solutions r√©volutionnaires
:showtitle:
:page-navtitle: Un design √©volutif pour des solutions r√©volutionnaires
:page-excerpt:
:layout: post
:author: saidboudjelda
:page-tags: [Algorithms, IA, Machine Learning, Optimisation, Programmation G√©n√©tique, Design, Evolution]
:page-vignette: genetics.png
:page-liquid:
:page-categories: Intelligence Artificielle, Algorithmes, Programmation g√©n√©tique

== Prelude

Il y a environ 13,8 milliards d'ann√©es, l'Univers tel que nous le connaissons a √©merg√© d'un √©v√©nement
d'une inimaginable densit√© et √©nergie : le *Big Bang*.
Cet instant initial ne fut pas une explosion dans l'espace,
mais plut√¥t une expansion de l'espace lui-m√™me.
Le temps, l'espace et la mati√®re sont n√©s ensemble, jaillissant d'une singularit√© myst√©rieuse.

Dans ses premiers instants, l'Univers √©tait une soupe chaude et dense de particules √©l√©mentaires :
quarks, √©lectrons, photons et autres.
√Ä mesure qu'il s'√©tendait, cette soupe refroidit.

Quelques centaines de milliers d'ann√©es apr√®s le Big Bang, les quarks se li√®rent pour former des
protons et des neutrons, et ces derniers se combin√®rent pour donner naissance aux premiers noyaux
atomiques.

Les scientifiques estiment qu'il existe environ 10‚Å∏‚Å∞ atomes dans l'Univers visible, soit un
chiffre gigantesque : un 1 suivi de 80 z√©ros.
Ce nombre colossal a √©t√© calcul√© en combinant plusieurs observations et hypoth√®ses.

Et dans un autre univers qui est l'univers *math√©matique*.
Il existe des nombres qui sont encore plus grand que le nombre d'atomes et de loin, et voici deux exemples :

Nous avons sequence de lettres *``ABC``* et nous voulons trouver toutes les permutations possibles, c'est-√†-dire
**``ABC``**, **``ACB``**, **``BAC``**, **``BCA``**, **``CAB``**, **``CBA``**, soit un total de ``6`` permutations.

Mais imaginez maintenant que nous devons trouver la meilleure solution pour le probl√®me Suivant :
Un voyageur doit visiter un ensemble de ùëõ villes, chacune exactement une fois, avant de revenir √† sa ville de d√©part.
Les distances entre les villes sont connues, et le but est de d√©terminer l'itin√©raire qui minimise la distance totale
parcourue et/ou le co√ªt total.

Si on veut une representation math√©matiques de ce probl√®me, on peut le d√©finir comme suit :
Soit \(ùëâ = \{c_1, c_2, c_3,..., c_ùëõ\} \) l'ensemble des villes √† visiter, et \( d(i, j) \) la distance entre les villes ùëñ et ùëó.
Une matrice de distance \((D)\) est d√©finie telle que \( D[i, j] \) = \( d(i, j) \) pour tout ùëñ, ùëó ‚àà ùëâ.

En sortie, nous aurons besoin de trouver une permutation \(ùúã = (ùúã_1, ùúã_2, ..., ùúã_ùëõ) \) de l'ensemble \(ùëâ\) telle que le
cout total de la tourn√©e soit minimal, c'est-√†-dire que la somme des distances entre les villes successives :

stem:[\text{t}(\pi) = \sum_{i=1}^{n-1} D[\pi_i, \pi_{i+1}\]]

Et si on calcule la complexit√© de ce probl√®me, on trouve qu'il est de l'ordre de \(O(n!)\) footnote:fact[La fonction
factorielle, not√©e ùëõ!, est une op√©ration math√©matique qui multiplie tous les entiers positifs d‚Äôun nombre ùëõ jusqu'√† 1.
Elle est utilis√©e dans de nombreux domaines comme les probabilit√©s, les statistiques, les algorithmes et la combinatoire.
\(n! = n √ó (n - 1) √ó (n - 2) √ó ... √ó 2 √ó 1\)]
ce qui est tr√®s couteux car :

Par exemple, pour stem:[\begin{equation} ùëõ = 10 \end{equation}] il y'a stem:[\begin{equation}9!= 362,880 \end{equation}]
chemins √† explorer.

Pour stem:[\begin{equation} ùëõ = 20\end{equation}] il y a  stem:[\begin{equation} 19!‚âà 1.22 * 10^{17} \end{equation}]
footnote:nb[Le nombre stem:[\begin{equation} 19!‚âà 1.22 * 10^{17} \end{equation}] est une notation scientifique utilis√©e
pour repr√©senter des nombres tr√®s grands ou tr√®s petits de mani√®re concise.
Voici comment l‚Äôinterpr√©ter en valeur exacte 1.22√ó100,000,000,000,000,000 = 122,000,000,000,000,000 ou 122 quadrillions.] et
pour 71 villes, le nombre de chemins candidats est sup√©rieur √† stem:[\begin{equation} 70!‚âà 5 * 10^{99} \end{equation}]
qui est plus grand que le nombre d'atomes dans l'univers connu ce qui devient ing√©rable pour un ordinateur.
footnote:atoms[Le nombre d'atomes dans l'univers observable est estim√© √† environ 10^80, ce qui signifie que le nombre
de chemins possibles pour 71 villes d√©passe largement ce nombre, en 2004, Carl Sagan a popularis√© dans Cosmos l‚Äôid√©e du
nombre d‚Äôatomes dans l‚Äôunivers observable en discutant de
l‚Äôimmensit√© de l‚Äô√©space]

On appelle ce probl√®me le probl√®me du voyageur de commerce *(TSP, Travelling Salesman Problem)*

image::{{'/images/tsp/traveling.png' | relative_url}}[image,align="center"]

== Introduction

Les algorithmes exacts (d√©terministes) jouent un r√¥le fondamental dans la r√©solution de nombreux probl√®mes dans divers domaines,
qu'il s'agisse de tri de donn√©es, de recherche de chemins optimaux, ou encore de r√©solution d‚Äô√©quations complexes.

Cependant, face √† des probl√®mes dits `NP-difficiles' footnote:np-difficult[En informatique th√©orique,
le terme "NP-difficiles" (ou NP-hard en anglais) d√©signe une classe
de probl√®mes qui sont au moins aussi difficiles √† r√©soudre que les probl√®mes de la classe
NP (Non-deterministic Polynomial time); Example : Le c√©l√®bre probl√®me du voyageur de commerce
(TSP, Travelling Salesman Problem) en version d‚Äôoptimisation qui consiste √† trouver le chemin optimal
parmi plusieurs villes est un d√©fi immense quand le nombre de villes augmente] ou √† de vastes espaces de conception,
ils r√©v√®lent rapidement leurs limites.

Ces algorithmes, souvent d√©terministes, sont con√ßus pour parcourir de mani√®re exhaustive toutes les solutions possibles
pour garantir de trouver l‚Äôoptimum, ce qui rend leur utilisation peu pratique, voire impossible, pour des probl√®mes de
grande dimension ou en constante √©volution.

Les algorithmes approximatifs ou m√©ta-heuristiques footnote:meta[Les m√©ta-heuristiques sont des m√©thodes d'optimisation
avanc√©es con√ßues pour r√©soudre des probl√®mes complexes, souvent difficiles √† traiter par des algorithmes exacts en
raison de la taille ou de la complexit√© de l'espace de recherche. Ces approches utilisent des strat√©gies globales
et adaptatives pour explorer efficacement l'espace des solutions et trouver des solutions optimales ou
quasi-optimales dans un temps raisonnable], quant √† eux, apportent une approche diff√©rente pour obtenir des solutions
proches de l'optimum dites quasi-optimales dans des d√©lais raisonnables, ce qui est souvent suffisant pour
les applications pratiques.

Une des classes des m√©ta-heuristiques est celle des algorithmes √©volutionnaires, souvent assimil√©s aux
'algorithmes g√©n√©tiques' dont l'approche est inspir√©e des m√©canismes de l'√©volution naturelle.

En simulant des processus tels que la s√©lection, le croisement et la mutation, les algorithmes √©volutionnaires
g√©n√®rent progressivement des solutions optimales ou quasi-optimales contrairement aux algorithmes exactes qui peuvent
√™tre bloqu√©s par des solutions locales ou des configurations complexes.

Au-del√† de la r√©solution de probl√®mes sp√©cifiques, les algorithmes √©volutionnaires se distinguent par leur efficacit√©
dans l'exploration d'espaces de recherche vastes et complexes, surtout lorsque les dimensions du probl√®me augmentent
et entra√Ænent une prolif√©ration de configurations possibles.

Ces algorithmes apportent une dynamique adaptative et flexible, √©largissant consid√©rablement le champ de recherche
en p√©n√©trant des zones inexplor√©es et souvent inaccessibles aux m√©thodes classiques ou √† l'intuition humaine.
Cette capacit√© d'exploration, amplifi√©e par la composante al√©atoire, ouvre la voie √† la d√©couverte de solutions innovantes,
in√©dites et potentiellement optimis√©es, qui auraient autrement √©chapp√© √† toute d√©tection.

Par cons√©quent, nous utilisons les algorithmes √©volutionnaires pour concevoir de nouveaux produits ou syst√®mes
de mani√®re similaire √† la m√©thodes MVP (Minimum Viable Product). footnote:mvp[Il peut y avoir une grande similitude avec
le terme MVP utilis√© dans l'industrie logicielle ou par les m√©thodologies *Agile*, *SaFe* ou *Lean*; ici,
le produit peut √™tre la solution que nous cherchons √† notre probl√®me.]

Imaginez les algorithmes √©volutionnaires comme un processus de d√©veloppement en plusieurs g√©n√©rations :
au lieu de cr√©er un produit final parfait d√®s le d√©but, ils explorent diverses versions ``prototypes'' (solutions)
√† travers des it√©rations rapides.

Chaque version est test√©e, puis les meilleures configurations sont s√©lectionn√©es, ajust√©es et combin√©es pour former
une nouvelle g√©n√©ration am√©lior√©e.
De la m√™me fa√ßon que le MVP √©volue par √©tapes en fonction du retour des utilisateurs, les algorithmes √©volutionnaires
√©valuent, adaptent et optimisent chaque it√©ration pour s‚Äôapprocher de la solution optimale.

√âvidemment, au contraire du MVP, les algorithmes √©volutionnaires ne sont pas tenus de produire une solution
imm√©diatement ``viable`` ou utilisable √† chaque it√©ration.
Ils √©voluent de mani√®re it√©rative afin d'explorer l'espace de recherche pour converger progressivement vers des solutions optimales.
Dans ce contexte, on utilise un crit√®re de fitness pour √©valuer et comparer les solutions, permettant de s√©lectionner
et d'am√©liorer les meilleures configurations √† chaque g√©n√©ration, m√™me si elles ne sont pas directement applicables dans l‚Äôimm√©diat.

=== Simple comparaison entre le calcul des permutations et le probl√®me du voyageur de commerce (TSP)
Le calcul des permutations et le probl√®me du voyageur de commerce (TSP) illustrent bien la diff√©rence entre un probl√®me
exact et d√©terministe et un probl√®me n√©cessitant une m√©taheuristique.
Le calcul des permutations consiste √† g√©n√©rer toutes les combinaisons possibles d'un ensemble donn√©,
ce qui est un probl√®me exact : il n'a pas de contraintes sp√©cifiques, et un algorithme d√©terministe peut produire
l'ensemble complet des solutions avec une complexit√© de `O(n!)`.
En revanche, le TSP, qui vise √† trouver le chemin
le plus court visitant un ensemble de villes, est un probl√®me NP-difficile.
Il requiert de choisir une solution optimale parmi de nombreuses possibilit√©s tout en respectant des contraintes
(distances, co√ªts, etc.).

Bien que sa r√©solution exacte ait √©galement une complexit√© de `O(n!)`, cela devient impraticable pour de grands ensembles,
d'o√π le recours √† des m√©taheuristiques (comme les algorithmes g√©n√©tiques ou les colonies de fourmis) qui trouvent
des solutions approximatives, mais efficaces en temps r√©duit.
Ainsi, la permutation explore toutes les solutions possibles, tandis que le TSP n√©cessite d'identifier
la meilleure solution dans un espace de recherche beaucoup plus complexe.

[cols="3", options="header"]
|===
| **Aspect**              | **Calcul des Permutations**             | **Probl√®me du Voyageur de Commerce**

| **Objectif**            | G√©n√©rer toutes les solutions possibles. | Trouver la meilleure solution parmi toutes.
| **Solution requise**    | Ensemble complet des permutations.      | Un chemin optimal ou quasi-optimal.
| **Complexit√©**          | `O(n!)`                                 | `O(n!)` pour exact, mais m√©taheuristique r√©duit.
| **Contraintes**         | Aucune contrainte particuli√®re.         | Inclut des contraintes sp√©cifiques (distances, co√ªts).
| **Type d'algorithme**   | Exact et d√©terministe.                  | Exact (impraticable √† grande √©chelle) ou m√©taheuristique.
|===


== Les Algorithmes √âvolutionnaires : Inspir√©s par la Nature

Les algorithmes √©volutionnaires (AE) sont utilis√©s pour r√©soudre des probl√®mes complexes dans des domaines vari√©s,
notamment l‚Äôoptimisation combinatoire, l‚Äôapprentissage automatique, la robotique ou encore le design industriel.

Leur principe repose sur la repr√©sentation des solutions potentielles d‚Äôun probl√®me sous forme de chromosomes,
ou g√©notypes, qui peuvent √™tre cod√©s diff√©remment en fonction du probl√®me.

Ces repr√©sentations incluent les cha√Ænes binaires, adapt√©es aux probl√®mes combinatoires, les vecteurs de nombres r√©els,
souvent utilis√©s pour des probl√®mes continus, ou encore les permutations,
essentielles pour des probl√®mes comme le voyageur de commerce.

Le processus commence par la g√©n√©ration d‚Äôune population initiale d‚Äôindividus, qui peut √™tre al√©atoire ou
guid√©e par des heuristiques sp√©cifiques.
Chaque individu de cette population repr√©sente une solution candidate et est √©valu√© √† l‚Äôaide d‚Äôune fonction de fitness,
con√ßue pour mesurer la qualit√© de la solution en fonction des objectifs du probl√®me.

Cette fonction est souvent sp√©cifique au domaine et peut viser √† maximiser une performance, minimiser un co√ªt,
ou encore √©quilibrer plusieurs crit√®res dans des contextes multi-objectifs.
Sur la base de cette √©valuation, les individus les plus adapt√©s, c‚Äôest-√†-dire ceux pr√©sentant une meilleur fitness,
sont s√©lectionn√©s pour participer √† la reproduction, un processus cl√© dans lequel les solutions prometteuses sont
combin√©es pour explorer de nouvelles r√©gions de l‚Äôespace des solutions.

La s√©lection peut √™tre r√©alis√©e selon plusieurs m√©thodes.
La roulette probabiliste privil√©gie les individus les plus performants en proportion de leur fitness, tandis que la
s√©lection par tournoi compare un sous-ensemble al√©atoire d‚Äôindividus pour ne retenir que les meilleurs.
La s√©lection par rang classe les individus par ordre de fitness pour attribuer des probabilit√©s √©quitables,
et les m√©canismes √©litistes garantissent la pr√©servation des solutions les plus prometteuses en les transmettant
directement √† la g√©n√©ration suivante.
Une fois les parents choisis, le croisement entre leurs chromosomes produit de nouveaux individus appel√©s enfants.
Ce processus repose sur divers m√©canismes, tels que le croisement √† un point ou √† deux points, o√π des portions des
chromosomes des parents sont √©chang√©es, ou encore le croisement uniforme, o√π chaque g√®ne est m√©lang√© de mani√®re ind√©pendante.

Cette recombinaison favorise la cr√©ation de nouvelles combinaisons g√©n√©tiques qui peuvent conduire √† de meilleures solutions.

En parall√®le, la mutation joue un r√¥le crucial pour maintenir la diversit√© dans la population.
Elle introduit des changements al√©atoires dans les chromosomes en inversant des bits pour les repr√©sentations binaires,
ou en ajoutant de petites perturbations pour les vecteurs r√©els.
Cela permet d‚Äô√©viter la stagnation dans des solutions sous-optimales et de pr√©server la capacit√© de l‚Äôalgorithme √†
explorer des r√©gions peu visit√©es de l‚Äôespace de recherche.
Une fois la phase de croisement et de mutation termin√©e, une nouvelle population est form√©e, soit en rempla√ßant
enti√®rement l‚Äôancienne population, soit en combinant les anciens et les nouveaux individus, souvent en privil√©giant les plus performants.

Ce cycle d‚Äô√©valuation, s√©lection, reproduction et mutation se poursuit de mani√®re it√©rative, g√©n√©ration apr√®s g√©n√©ration,
jusqu‚Äô√† ce qu‚Äôune condition d‚Äôarr√™t soit atteinte.
Ces conditions peuvent inclure l‚Äôatteinte d‚Äôun nombre maximal de g√©n√©rations, la convergence de la population vers une
solution stable, ou l‚Äôobtention d‚Äôune solution jug√©e satisfaisante en fonction des crit√®res d‚Äô√©valuation.
√Ä la fin de ce processus, l‚Äôalgorithme retourne la meilleure solution trouv√©e, g√©n√©ralement celle associ√©e √†
la fitness la plus √©lev√©e dans la population finale.

Les algorithmes √©volutionnaires se distinguent par leur approche stochastique et approximative, qui ne garantit
pas toujours la solution optimale, mais leur conf√®re une robustesse et une adaptabilit√© remarquables.
Leur capacit√© √† √©quilibrer l‚Äôexploration de nouvelles solutions avec l‚Äôexploitation des meilleures
solutions actuelles en fait des outils puissants pour r√©soudre des probl√®mes dans des espaces de recherche vastes,
discontinus ou non convexes.
Cette flexibilit√© et cette efficacit√© leur permettent de s‚Äôimposer dans de nombreux domaines o√π d‚Äôautres m√©thodes
traditionnelles d‚Äôoptimisation peuvent √©chouer.

== Types des EAs

=== Algorithmes g√©n√©tiques (AG)

Les algorithmes g√©n√©tiques (AG) sont des m√©taheuristiques inspir√©es du processus de l'√©volution naturelle,
qui utilisent des m√©canismes de s√©lection, croisement, mutation et reproduction pour r√©soudre des probl√®mes
d'optimisation et de recherche.
Ils font partie des algorithmes √©volutionnaires et sont utilis√©s dans de nombreux domaines, tels que l'optimisation
combinatoire, la recherche op√©rationnelle, l'intelligence artificielle, et bien d'autres.

Les algorithmes g√©n√©tiques sont bas√©s sur la s√©lection naturelle et la g√©n√©tique.
Ils visent √† imiter le processus biologique de l‚Äô√©volution, o√π les individus les mieux adapt√©s survivent et
se reproduisent, tandis que les moins adapt√©s disparaissent.
Voici les √©tapes g√©n√©rales d'un algorithme g√©n√©tique

* *Initialisation de la population*: Cr√©er une population initiale d'individus (solutions potentielles).
Chaque individu est repr√©sent√© par un chromosome (g√©n√©ralement sous forme de cha√Æne binaire ou de vecteur de valeurs r√©elles).
Cette population peut √™tre g√©n√©r√©e al√©atoirement ou bas√©e sur des heuristiques l'objectif de cette √©tape est de cr√©er
une population de solutions diverses pour explorer un large espace de recherche.

* *√âvaluation de la fitness*: Chaque individu de la population est √©valu√© en fonction de sa fitness (aptitude).
La fitness est une mesure de la qualit√© de la solution, selon une fonction d'√©valuation pr√©d√©finie, qui peut varier en
fonction du probl√®me sp√©cifique l'objectif de cette √©tape est de d√©terminer √† quel point chaque individu est "bon"
ou proche de la solution optimale.

* *S√©lection*: S√©lectionner les individus qui vont participer √† la reproduction, g√©n√©ralement en fonction de leur fitness.

* *Croisement (Crossover)*: Le croisement est l'op√©ration qui combine deux parents pour cr√©er un ou plusieurs enfants.
Ce processus √©change des portions des chromosomes des parents pour g√©n√©rer de nouvelles solutions.

=== Programmation √©volutionnaire (EP)

La programmation √©volutionnaire (EP) est une approche d'optimisation stochastique inspir√©e de l'√©volution biologique,
qui fait partie des algorithmes √©volutionnaires.
Elle a √©t√© introduite dans les ann√©es 1960 par *Ingo Rechenberg* et *Hans-Paul Schwefel* pour r√©soudre des probl√®mes
d'optimisation complexes, principalement dans le cadre de l'ing√©nierie et de la conception de syst√®mes.
La programmation √©volutionnaire se distingue des autres algorithmes √©volutionnaires (comme les algorithmes g√©n√©tiques)
par son approche simplifi√©e et la mani√®re dont elle g√®re la population et la s√©lection des solutions candidates.

=== Programmation g√©n√©tique (GP)

La programmation g√©n√©tique (GP) est utilis√©e pour g√©n√©rer des programmes informatiques capables de r√©soudre des probl√®mes complexes.
Contrairement aux algorithmes g√©n√©tiques classiques qui manipulent des vecteurs de r√©els ou des cha√Ænes binaires,
GP utilise des arbres de syntaxe o√π les n≈ìuds repr√©sentent des op√©rateurs et les feuilles des constantes ou des variables.

Le processus commence par une population initiale d'arbres g√©n√©r√©s al√©atoirement, suivie de l'√©valuation de leur
performance √† r√©soudre le probl√®me via une fonction de fitness.
Ensuite, les meilleurs individus sont s√©lectionn√©s pour la reproduction, o√π le croisement et la mutation sont utilis√©s
pour g√©n√©rer de nouvelles solutions.

GP est appliqu√©e dans des domaines vari√©s, tels que la cr√©ation automatique de logiciels,
l'optimisation de mod√®les d'apprentissage automatique, la conception de circuits √©lectroniques,
la g√©n√©ration de strat√©gies de jeu et la cr√©ation d'algorithmes d'optimisation.

Par exemple, dans la cr√©ation de logiciels, GP peut √™tre utilis√©e pour g√©n√©rer automatiquement des programmes
de traitement d'image ou pour optimiser des architectures de r√©seaux neuronaux.

Elle est √©galement utilis√©e pour concevoir des circuits logiques, g√©n√©rer des strat√©gies de jeu dans des simulations,
ou encore optimiser des syst√®mes complexes comme la gestion des ressources dans l'industrie.

=== Algorithmes √©volutionnaires multi-objectifs (MOEA)

Les MOEA sont une classe d'algorithmes √©volutionnaires con√ßus pour r√©soudre des probl√®mes d'optimisation impliquant
plusieurs objectifs simultan√©ment.
Contrairement aux probl√®mes d'optimisation classiques o√π un seul objectif est maximis√© ou minimis√©, les probl√®mes
multi-objectifs comportent plusieurs crit√®res contradictoires ou compl√©mentaires √† prendre en compte, l'objectif
est de trouver un ensemble de solutions optimales, appel√©es *Front Pareto* footnote:frontpareto[La fronti√®re de Pareto,
ou front de Pareto, est un concept fondamental dans l'optimisation multi-objectifs.
Elle repr√©sente l'ensemble des solutions non domin√©es dans un probl√®me o√π plusieurs crit√®res ou objectifs
sont pris en compte.
Dans ce contexte, une solution est dite domin√©e si une autre solution est au moins aussi
bonne dans tous les objectifs et strictement meilleure dans au moins un objectif.
Les solutions non domin√©es forment donc ce qu'on appelle la fronti√®re de Pareto.]

], plut√¥t qu'une seule solution optimale.
Le front de Pareto repr√©sente un ensemble de solutions o√π aucune ne peut √™tre am√©lior√©e dans un objectif sans
d√©t√©riorer un autre objectif.

=== √âvolution diff√©rentielle (DE)

L'√©volution diff√©rentielle (DE, pour Differential Evolution) est un algorithme √©volutionnaire utilis√© principalement
pour r√©soudre des probl√®mes d'optimisation continues dans des espaces de recherche de grande dimension.
Il a √©t√© propos√© pour la premi√®re fois par *Rainer Storn* et *Kenneth Price* en 1995.
L'√©volution diff√©rentielle est similaire aux autres algorithmes √©volutionnaires (comme les algorithmes g√©n√©tiques),
mais elle se distingue par ses op√©rateurs de mutation et de croisement sp√©cifiques

L'id√©e principale de l'√©volution diff√©rentielle est d'utiliser des diff√©rences vectorielles entre des individus
(solutions candidates) pour g√©n√©rer de nouvelles solutions.L'algorithme repose sur trois op√©rateurs principaux
: mutation, croisement et s√©lection.

* *Mutation*: La mutation dans DE est r√©alis√©e en combinant les diff√©rences entre des solutions (ou individus)
pour cr√©er de nouvelles solutions candidates.
Plus pr√©cis√©ment, une diff√©rence entre deux solutions de la population est ajout√©e √† une troisi√®me solution
pour produire un individu mutant.
stem:[v_i = x_{r1} + F \cdot (x_{r2} - x_{r3})]
o√π :
- stem:[v_i] est le vecteur mutant,
- stem:[x_{r1}], stem:[x_{r2}], et stem:[x_{r3}] sont des solutions s√©lectionn√©es al√©atoirement dans la population,
- stem:[F] est un facteur de mutation qui contr√¥le l'amplitude de la mutation.

* *Croisement (Recombinaison)* : L'op√©rateur de croisement combine la solution d'origine (parents) avec la
solution mutant pour produire un nouvel individu.
Le croisement est g√©n√©ralement r√©alis√© avec un taux de croisement CR, qui d√©termine la probabilit√© qu'un
√©l√©ment de la solution mutant soit remplac√© par l'√©l√©ment correspondant de la solution de d√©part.

* *S√©lection* : Une fois que l'individu mutant (ou recombin√©) a √©t√© g√©n√©r√©, il est compar√© √† la solution originale
(c'est-√†-dire son parent).
Si la solution mutant est meilleure (selon la fonction de fitness), elle remplace la solution originale dans la population,
sinon l'individu original est conserv√©.
Cela permet de garantir que la population ne se d√©t√©riore pas au fil des g√©n√©rations.

La mutation dans DE repose sur une approche novatrice qui exploite les diff√©rences entre individus pour produire des solutions prometteuses.
Cette m√©thode permet un compromis efficace entre exploration (recherche dans de nouvelles zones) et exploitation
(raffinement des solutions actuelles).
Les param√®tres comme le facteur ùêπ et la strat√©gie de mutation choisie jouent un r√¥le crucial dans la performance de l'algorithme.

*Application concr√®te*: Optimisation des hyperparam√®tres dans les r√©seaux de neurones ou dans des syst√®mes o√π la solution
est un vecteur continu, comme l'optimisation de la trajectoire d'un robot autonome en utilisant des donn√©es sensorielles.

=== Algorithmes m√©m√©tiques

Les algorithmes m√©m√©tiques (ou algorithmes de la m√©moire), parfois appel√©s m√©taheuristiques hybrides, sont une classe
d'algorithmes d'optimisation qui combinent les algorithmes √©volutionnaires (comme les algorithmes g√©n√©tiques) avec
des techniques locales de recherche (souvent appel√©es descentes locales ou m√©thodes de voisinage).
L'objectif principal des algorithmes m√©m√©tiques est d'am√©liorer l'efficacit√© de la recherche en combinant la capacit√©
d'exploration globale des algorithmes √©volutionnaires avec la capacit√© d'exploitation locale des m√©thodes de recherche locale.

=== Algorithmes co-√©volutionnaires

Les algorithmes co-√©volutionnaires sont une classe d'algorithmes d'optimisation qui s'inspirent du concept de
co√©volution biologique, o√π deux ou plusieurs populations √©voluent simultan√©ment en r√©ponse aux changements
que chacune subit de l'autre.

Ces algorithmes sont souvent utilis√©s dans des contextes o√π les solutions optimales sont d√©pendantes des
interactions entre diff√©rents agents ou √©l√©ments.

L'id√©e derri√®re les algorithmes co-√©volutionnaires est que les individus d'une population √©voluent en r√©ponse aux
pressions exerc√©es par d'autres populations ou entit√©s avec lesquelles ils interagissent.
Cela peut √™tre appliqu√© dans divers domaines, comme l'optimisation multi-objectifs, la r√©solution de probl√®mes
combinatoires complexes, ou m√™me dans les jeux et la robotique.

* *Populations multiples* : Contrairement aux algorithmes √©volutionnaires classiques qui font √©voluer une seule population,
un algorithme co-√©volutionnaire fait √©voluer plusieurs populations en parall√®le.
Chaque population est compos√©e d'individus (solutions potentielles) qui interagissent avec les individus d'autres populations.

* *Interactions entre populations* : Les individus d'une population sont souvent √©valu√©s en fonction de leur performance
non seulement vis-√†-vis de crit√®res internes (comme dans les algorithmes √©volutionnaires classiques), mais aussi par
rapport √† l'interaction avec d'autres individus, qui peuvent √™tre d'une population diff√©rente.

Chaque type d'algorithme √©volutionnaire est adapt√© √† des types sp√©cifiques de probl√®mes.
Les AG et les MOEA sont parmi les plus polyvalents, tandis que des approches comme la programmation g√©n√©tique ou
l'√©volution diff√©rentielle r√©pondent √† des besoins plus sp√©cialis√©s.
En fonction des contraintes et des objectifs, ces algorithmes peuvent √™tre combin√©s ou modifi√©s pour maximiser
leur efficacit√© dans le design ou l‚Äôoptimisation.

== L'utilisation des algorithmes √©volutionnaires dans le design

Nous avons deja presenter le probl√®me de voyageur de commerce (TSP) qui est un classique en optimisation combinatoire et
dans lequel les algorithmes √©volutionnaires ont montr√© leur efficacit√©.

Consid√©rer comme un probl√®me abstrait, mais il est en fait tr√®s concret et trouve des applications dans de nombreux domaines.
Par exemple, dans la logistique, le TSP est utilis√© pour optimiser les tourn√©es de livraison, minimiser les co√ªts de
transport et r√©duire les √©missions de CO2.

Dans le domaine de la fabrication, il est utilis√© pour planifier les itin√©raires des robots ou des machines,
minimiser les temps de production et maximiser l'efficacit√© des op√©rations.

Dans le secteur des t√©l√©communications, il est utilis√© pour optimiser les r√©seaux de communication,
minimiser les temps de latence et maximiser la bande passante disponible.
Et dans le domaine de la recherche op√©rationnelle, il est utilis√© pour r√©soudre des probl√®mes de distribution,

*Mais comment l'utiliser dans notre domaine √† nous qui sommes le la conception et l'architecture d√©veloppement logiciel ?*


== Les applications des algorithmes √©volutionnaires dans le design
Les *algorithmes √©volutionnaires (A√â)* sont largement utilis√©s dans le domaine du *design* gr√¢ce √† leur capacit√© √†
explorer efficacement de vastes espaces de solutions et √† optimiser des probl√®mes complexes.
Dans le *design industriel*, ils permettent de cr√©er des produits innovants en optimisant des crit√®res comme
la **r√©sistance**, le **poids** ou le **co√ªt**, par exemple pour concevoir des formes a√©rodynamiques ou des composants m√©caniques.
En *architecture* et *design urbain*, les A√â sont employ√©s pour g√©n√©rer des **plans de b√¢timents** ou des
**mod√®les urbains** r√©pondant √† des contraintes environnementales ou esth√©tiques. Dans le *design g√©n√©ratif*,
ils aident √† explorer des concepts cr√©atifs en g√©n√©rant automatiquement des **formes artistiques** ou des
**patrons visuels**. Enfin, dans le *design d'interfaces* ou de syst√®mes, les A√â sont utilis√©s pour optimiser
les **flux d'interaction** ou concevoir des **interfaces utilisateur** efficaces et intuitives.


== Java et les algorithmes √©volutionnaires

Le langage java est un choix populaire pour impl√©menter des algorithmes √©volutionnaires en raison de sa simplicit√©,
robustesse et performance, et portability sur de nombreuses plateformes, voici quelques biblioth√®ques et frameworks :

=== JMetal
https://jmetal.readthedocs.io:[jMetal, window=_blank] est un framework java opensource
footnote:jmetal[Le code source de jMetal est disponible sur Github https://github.com/jMetal/jMetal:[jMetal Github]],
qui fournit une collection est une biblioth√®que Java d√©di√©e √† l'optimisation multi-objectifs.
Elle offre un ensemble d'outils pour r√©soudre des probl√®mes d'optimisation o√π plusieurs objectifs doivent √™tre simultan√©ment optimis√©s.
Ces probl√®mes sont fr√©quents dans des domaines comme la gestion de la production,
la conception de syst√®mes, la planification, l'ing√©nierie, etc. jMetal fournit une collection d'algorithmes
√©volutionnaires et des structures de donn√©es pour les utiliser de mani√®re flexible et extensible,
Il prend en charge plusieurs types d'algorithmes √©volutionnaires et techniques d'optimisation multi-objectifs, y compris :

* Algorithmes g√©n√©tiques (AG)
* Programmation √©volutionnaire (EP)
* Programmation g√©n√©tique (GP)
* Algorithmes √©volutionnaires multi-objectifs (MOEA) comme NSGA-II footnote:nsga[*NSGA-II (Non-dominated Sorting Genetic Algorithm II)*
 est un algorithme d'optimisation multi-objectifs largement utilis√© en recherche op√©rationnelle et en informatique pour
 r√©soudre des probl√®mes complexes impliquant plusieurs objectifs conflictuels.
 Il s'appuie sur les principes de l'√©volution naturelle, comme la s√©lection, la mutation et le croisement,
 et est particuli√®rement adapt√© pour des probl√®mes o√π l'espace des solutions est vaste et difficile
 √† explorer par des m√©thodes traditionnelles.], SPEA2 footnote:spea2[*SPEA2 (Strength Pareto Evolutionary Algorithm 2)*
 est un algorithme √©volutionnaire con√ßu pour r√©soudre des probl√®mes d'optimisation multi-objectifs.
 Il s'agit d'une am√©lioration du premier algorithme SPEA (Strength Pareto Evolutionary Algorithm),
 visant √† trouver un ensemble de solutions qui approximent la fronti√®re de Pareto du probl√®me,
 c'est-√†-dire l'ensemble des solutions non domin√©es o√π aucune solution n'est strictement meilleure
 qu'une autre dans tous les objectifs.], IBEA footnote:ibea[*IBEA (Indicator-Based Evolutionary Algorithm)*
 est un algorithme √©volutionnaire con√ßu pour r√©soudre des probl√®mes d'optimisation multi-objectifs.
 Il se distingue des autres algorithmes multi-objectifs en utilisant des indicateurs pour guider
 la recherche de solutions plut√¥t que de se baser uniquement sur les principes de dominance de Pareto.
 L'IBEA est particuli√®rement adapt√© aux probl√®mes complexes o√π il est difficile de d√©finir une fonction
 de dominance simple, et il a pour objectif d'optimiser √† la fois la convergence (proximit√© de Front de Pareto)
 et la diversit√© (r√©partition des solutions)], etc.
* Optimisation par colonies de fourmis, etc.

Il est principalement utilis√© dans des contextes o√π plusieurs objectifs sont en jeu et o√π il n'y a pas de solution
unique optimale, mais plut√¥t un ensemble de solutions compromis, connu sous le nom de *front de Pareto*

=== MOEA Framework
https://www.moeaframework.org:[MOEA Framework, window=_blank] est une biblioth√®que Java open-source
footnote:moea[Le code source de la biblioth√®que se trouve sur ce lien :
https://github.com/MOEAD/moea-framework:[MOEA GitHub, window=_blank]] con√ßue pour
l'optimisation multi-objectifs bas√©e sur des algorithmes √©volutionnaires. Elle est tr√®s populaire dans la communaut√©
de la recherche et de l‚Äôindustrie pour r√©soudre des probl√®mes o√π plusieurs objectifs doivent √™tre optimis√©s simultan√©ment.
Le framework offre une large gamme d'algorithmes d'optimisation multi-objectifs et des outils pour l‚Äô√©valuation,
la gestion et la visualisation des r√©sultats.

Le MOEA Framework permet de r√©soudre des probl√®mes complexes en utilisant des algorithmes √©volutionnaires multi-objectifs.
Il offre plusieurs algorithmes, y compris des versions avanc√©es de NSGA-II, SPEA2, MOEA/D, NSGA-III,
et d'autres techniques populaires d'optimisation.

Le framework est con√ßu pour √™tre extensible et personnalisable, permettant aux utilisateurs de d√©finir leurs propres probl√®mes,
algorithmes et op√©rateurs d'√©volution.

=== Opt4J
https://github.com/sdarg/opt4j:[Opt4J, window=_blank] est une biblioth√®que Java pour l'optimisation bas√©e sur les
``m√©taheuristiques``, particuli√®rement adapt√©e pour la recherche.
Elle offre une int√©gration modulaire, ce qui permet de combiner diff√©rents algorithmes pour r√©soudre des probl√®mes d'optimisation.

=== ECJ
ECJ (Evolutionary Computation in Java) est un syst√®me de calcul √©volutionnaire √©crit en Java.
Il a √©t√© con√ßu pour √™tre extr√™mement flexible, permettant aux utilisateurs de configurer presque toutes les classes
et leurs param√®tres dynamiquement √† l'ex√©cution √† l'aide d'un fichier de param√®tres fourni par l'utilisateur.
Les structures du syst√®me sont organis√©es de mani√®re √† √™tre facilement modifiables tout en maintenant une grande efficacit√©.

ECJ est d√©velopp√© par l'ECLab (Evolutionary Computation Laboratory) de l'Universit√© George Mason.
Bien qu'il partage ses initiales avec Evolutionary Computation Journal, le logiciel n'a aucun lien avec cette publication.
ECJ poss√®de un projet "s≈ìur" appel√© MASON, un syst√®me de simulation multi-agents con√ßu pour bien s'int√©grer avec ECJ.


== Les algorithmes √©volutionnaires au c≈ìur des architectures cloud
Dans un ou plusieurs clusters Kafka compos√©s de plusieurs brokers par cluster,
avec une infrastructure de communication cellulaire `5G`, des milliers de capteurs IoT, une diversit√©
d'API utilisant diff√©rents protocoles, et des milliers de microservices et d'applications, nous faisons face √† un
probl√®me d'optimisation complexe footnote:[Ce type d'architecture n'est pas une hypoth√®se th√©orique,
mais une r√©alit√© dans le domaine du cloud
computing et de l'IoT.
Par exemple, une ville intelligente connecte des milliers de capteurs IoT pour surveiller
divers aspects comme la qualit√© de l'air, la circulation, ou encore la gestion des d√©chets.].

image::{{'/images/tsp/smart_city.jpeg' | relative_url}}[image, align="center"]

=== Question


Comment d√©terminer une architecture optimale pour nos cluster(s) Kafka et la configuration des different brokers et
la taille des machines (RAM, CPU, DISK, Network ...) √† utiliser pour chaque n≈ìud de  pour minimiser la latence et
maximiser le d√©bit, afin que nos microservices puissent √©changer les donn√©es en temps r√©el, tout en tenant compte des
contraintes telles que la scalabilit√©, le temps de r√©ponse et les co√ªts ?

=== R√©soudre le probl√®me avec une approche traditionnelle
Une approche classique consisterait √† tester manuellement toutes les architectures et leurs configurations possibles.
Ce qui doit √™tre extr√™mement co√ªteux en temps et en ressources, car une approche intuitive serait de :
prendre une arbitraire architecture `A1` avec une configuration des composants et service `C1`, effectuer un test reel
et attendre les r√©sultats apres un certain temps, faire un benchmarking pour passer √† une configuration `C2`, ce qui peut
impliquer de changer la taille des machines, le nombre de brokers, le nombre de partitions, etc.
Et faire la meme chose avec une autre architecture `A2`, `A3`, etc.

Cependant, avec *stem:[\begin{equation} 10 \end{equation}]* broker pouvant avoir
*stem:[\begin{equation} 10 \end{equation}]* configurations possibles, cela donne un total de
*stem:[\begin{equation} 10^{10} \end{equation}]* configurations.
Tester un tel volume est impraticable, m√™me avec des outils d'automatisation, en raison du temps requis et de la
complexit√© des param√®tres √† consid√©rer (latence r√©seaux, partitions, charge, m√©moire, CPU, disponibilit√©, etc.)

=== NSGA-II : Une approche √©volutionnaire pour l‚Äôoptimisation multi-objectifs
Pour r√©soudre ce probl√®me efficacement, nous pouvons utiliser l'algorithme un des algorithmes commun√©ment utilis√©s dans
ce contexte qui est *NSGA-II (Non-dominated Sorting Genetic Algorithm II)*, une m√©thode bien adapt√©e aux probl√®mes
d'optimisation multi-objectifs.

Cet algorithme est con√ßu pour trouver des solutions optimales en √©quilibrant plusieurs objectifs contradictoires, tels que :
- Minimiser la latence.
- Maximiser les performances globales.
- R√©duire les co√ªts.
- Maximiser la scalabilit√©.

Tout en simulant les different configurations possibles, *NSGA-II* explore l'espace des solutions pour trouver un ensemble

==== √âtapes principales de NSGA-II :

1. **Initialisation** : G√©n√©rer une population initiale de configurations al√©atoires,
et pour exemple :

- Configuration 1 : `3` machine de `50BG` de RAM, `4` CPU de `16` c≈ìurs, `100GB` de disque,
`1GB/s` de r√©seau, et on va configurer 10 brokers par cluster avec `3` partitions par topic pour
un ensemble de topic 100.
- Configuration 2 : 1 Machine puissante de `100GB` de RAM, `8` CPU de `32` c≈ìurs, `500GB` de disque,
`10GB/s` de r√©seau, et on va configurer 5 brokers par cluster avec `5` partitions par topic pour
- Configuration 3 : 5 petites machines de `4` CPU chacune, `16GB` de RAM,
`1GB/s` de r√©seau, et on va configurer 20 brokers par cluster avec `2` partitions par topic pour avec une
solution stockage sur le cloud.

2. **√âvaluation** : Mesurer les performances de chaque configuration selon les objectifs (latence, d√©bit, etc.)
Nous gardons les configurations ayant les meilleurs tout en essayant de diversifier les solutions,
et on va √©valuer les performances de chaque configuration en fonction des objectifs d√©finis.

3. **Tri par domination** : Classer les solutions en fonction de leur non-domination.
Les solutions qui ne sont pas surpass√©es sur tous les objectifs appartiennent au "front de Pareto".
4. **Crowding distance** : Mesurer la diversit√© des solutions dans chaque rang de domination pour favoriser une
exploration √©quilibr√©e.
5. **Op√©rations g√©n√©tiques** :
- S√©lection des solutions les plus prometteuses.
- Recombinaison (croisement) pour g√©n√©rer de nouvelles configurations.
- Mutation : Nous ajoutons des modifications al√©atoires, comme r√©duire ou augmenter la quantit√© de RAM,
ajouter un autre type de machine ou modifier les r√®gles de mise √† l'√©chelle automatique.
Par exemple, une configuration avec `3 machines moyennes pourrait √™tre mut√©e pour ajouter une mise √† l'√©chelle automatique en fonction de la charge.
6. **It√©rations** : R√©p√©ter le processus sur plusieurs g√©n√©rations pour faire converger la population vers une solution optimale.

==== Avantages de NSGA-II :
- **Fronti√®re de Pareto** : Permet d'obtenir un ensemble de solutions optimales, laissant aux d√©cideurs le choix parmi
plusieurs compromis entre les objectifs.
- **Efficacit√© computationnelle** : R√©duit la complexit√© gr√¢ce √† des m√©canismes optimis√©s comme le tri
rapide des solutions domin√©es.
- **Diversit√© des solutions** : Garantit une exploration √©quilibr√©e de l'espace des configurations.
- **Adaptabilit√©** : Peut √™tre appliqu√© √† des probl√®mes complexes avec des objectifs multiples et contradictoires.

En utilisant NSGA-II, nous pouvons naviguer efficacement dans l'immense espace des configurations possibles et
d√©couvrir des solutions innovantes et performantes, tout en r√©pondant aux exigences multi-objectifs de notre syst√®me.

== Conclusion
Les algorithmes √©volutionnaires permettent de repenser le processus de design en combinant puissance de calcul et cr√©ativit√© humaine.
Ils offrent une approche unique pour cr√©er des produits, des structures et des syst√®mes innovants, fonctionnels et
adapt√©s aux besoins modernes.
Ou les methods et les outils transitionnels ne peuvent pas atteindre.

== References

[bibliography]
* Lawler, E.L., Lenstra, J.K., Rinnooy Kan, A.H.G., & Shmoys, D.B, *The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization*, Wiley, 1985
* P.J.E. Peebles, *Principles of Physical Cosmologye*, Princeton Univ Pr, Ewing, New Jersey, U.S.A, 1993.
* Eiben, A.E., & Smith, J.E., *Introduction to Evolutionary Computing*, Springer, 2003.
* M.Garey and D.Johnson, *Computers and Intractability. A Guide to the Theory of NP-Completeness.*, Freemann, San Francisco, 1979.
* C.M. Papadimitriou, *Computational Complexity*, Addison-Wesley, Reading, Massachusetts, 1994.
* D.E. Goldberg, *Genetic Algorithms in Search, Optimization, and Machine Learning*, Addison-Wesley, 1989.
* F. Neumann and C.~Witt, *Bioinspired Computation in Combinatorial Optimization: Algorithms and Their Computational Complexity*, Natural Computing Series, 2010.
